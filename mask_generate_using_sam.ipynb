{"cells":[{"cell_type":"code","execution_count":9,"id":"5fa21d44","metadata":{"id":"5fa21d44","executionInfo":{"status":"ok","timestamp":1754037495070,"user_tz":-330,"elapsed":5,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["# Copyright (c) Meta Platforms, Inc. and affiliates."]},{"cell_type":"markdown","id":"b7c0041e","metadata":{"id":"b7c0041e"},"source":["# Automatically generating object masks with SAM"]},{"cell_type":"markdown","id":"289bb0b4","metadata":{"id":"289bb0b4"},"source":["Since SAM can efficiently process prompts, masks for the entire image can be generated by sampling a large number of prompts over an image. This method was used to generate the dataset SA-1B.\n","\n","The class `SamAutomaticMaskGenerator` implements this capability. It works by sampling single-point input prompts in a grid over the image, from each of which SAM can predict multiple masks. Then, masks are filtered for quality and deduplicated using non-maximal suppression. Additional options allow for further improvement of mask quality and quantity, such as running prediction on multiple crops of the image or postprocessing masks to remove small disconnected regions and holes."]},{"cell_type":"code","execution_count":10,"id":"072e25b8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":42},"id":"072e25b8","executionInfo":{"status":"ok","timestamp":1754037495134,"user_tz":-330,"elapsed":62,"user":{"displayName":"","userId":""}},"outputId":"d334b41d-2247-4025-a2ab-b3211471df29"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n"]},"metadata":{}}],"source":["from IPython.display import display, HTML\n","display(HTML(\n","\"\"\"\n","<a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n","\"\"\"\n","))"]},{"cell_type":"code","source":[],"metadata":{"id":"-_Wg2ZkrmXhc","executionInfo":{"status":"ok","timestamp":1754037495135,"user_tz":-330,"elapsed":15,"user":{"displayName":"","userId":""}}},"id":"-_Wg2ZkrmXhc","execution_count":10,"outputs":[]},{"cell_type":"markdown","id":"c0b71431","metadata":{"id":"c0b71431"},"source":["## Environment Set-up"]},{"cell_type":"markdown","id":"47e5a78f","metadata":{"id":"47e5a78f"},"source":["If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."]},{"cell_type":"code","execution_count":11,"id":"4fe300fb","metadata":{"id":"4fe300fb","executionInfo":{"status":"ok","timestamp":1754037495136,"user_tz":-330,"elapsed":14,"user":{"displayName":"","userId":""}}},"outputs":[],"source":["using_colab = True"]},{"cell_type":"code","execution_count":null,"id":"0685a2f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0685a2f5","outputId":"417e1b51-71e2-48b9-a92b-387f6f594c39"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.6.0+cu124\n","Torchvision version: 0.21.0+cu124\n","CUDA is available: True\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Collecting git+https://github.com/facebookresearch/segment-anything.git\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-su45qfi4\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-su45qfi4\n","  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n"]}],"source":["if using_colab:\n","    import torch\n","    import torchvision\n","    print(\"PyTorch version:\", torch.__version__)\n","    print(\"Torchvision version:\", torchvision.__version__)\n","    print(\"CUDA is available:\", torch.cuda.is_available())\n","    import sys\n","    !{sys.executable} -m pip install opencv-python matplotlib\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n","\n","    !mkdir images\n","    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n","\n","    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"]},{"cell_type":"markdown","id":"fd2bc687","metadata":{"id":"fd2bc687"},"source":["## Set-up"]},{"cell_type":"code","execution_count":null,"id":"560725a2","metadata":{"id":"560725a2"},"outputs":[],"source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import cv2\n","import sys\n","sys.path.append(\"..\")\n","import hashlib\n","from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n"]},{"cell_type":"code","execution_count":null,"id":"ad354922","metadata":{"id":"ad354922"},"outputs":[],"source":["image1 = cv2.imread('/content/image_A.jpg')\n","image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n","\n","image2 = cv2.imread('/content/image_B.jpg')\n","image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)"]},{"cell_type":"code","execution_count":null,"id":"e0ac8c67","metadata":{"id":"e0ac8c67"},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","plt.imshow(image1)\n","plt.axis('off')\n","plt.show()\n","\n","plt.figure(figsize=(20,20))\n","plt.imshow(image2)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"68364513","metadata":{"id":"68364513"},"outputs":[],"source":["\n","def load_image_rgb(path):\n","    image = cv2.imread(path)\n","    if image is None:\n","        raise ValueError(f\"Image not found at {path}\")\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","def mask_hash(mask):\n","    return hashlib.md5(mask.astype(np.uint8).tobytes()).hexdigest()\n","\n","def generate_masks(image, sam_model):\n","    mask_generator = SamAutomaticMaskGenerator(\n","        model=sam_model,\n","        points_per_side=5,\n","        pred_iou_thresh=0.95,\n","        stability_score_thresh=0.95,\n","        crop_n_layers=1,\n","        crop_n_points_downscale_factor=1,\n","        min_mask_region_area=8,\n","    )\n","    return mask_generator.generate(image)\n","\n","def build_mask_dict(masks):\n","    mask_dict = {}\n","    for mask in masks:\n","        seg = mask['segmentation'].astype(np.uint8)\n","        key = mask_hash(seg)\n","        mask_dict[key] = seg\n","    return mask_dict\n","\n","def show_anns(image, anns):\n","    if len(anns) == 0:\n","        return\n","    sorted_anns = sorted(anns, key=lambda x: x['area'], reverse=True)\n","    ax = plt.gca()\n","    ax.set_autoscale_on(False)\n","    for ann in sorted_anns:\n","        m = ann['segmentation']\n","        img = np.ones((m.shape[0], m.shape[1], 3))\n","        color_mask = np.random.random((1, 3)).tolist()[0]\n","        for i in range(3):\n","            img[:, :, i] = color_mask[i]\n","        ax.imshow(np.dstack((img, m * 0.35)))\n","\n","sam_checkpoint = \"/content/sam_vit_h_4b8939.pth\"\n","sam = sam_model_registry[\"vit_h\"](checkpoint=sam_checkpoint)\n","sam.to(device=\"cuda\")\n","\n","\n","img_A = load_image_rgb(\"/content/image_A.jpg\")\n","img_B = load_image_rgb(\"/content/image_B.jpg\")\n","\n","\n","masks_A = generate_masks(img_A, sam)\n","masks_B = generate_masks(img_B, sam)\n","\n","\n","mask_dict_A = build_mask_dict(masks_A)\n","mask_dict_B = build_mask_dict(masks_B)\n","\n","\n","new_keys = set(mask_dict_B.keys()) - set(mask_dict_A.keys())\n","print(f\"New or changed objects in Image B: {len(new_keys)}\")\n","\n","\n","plt.figure(figsize=(10, 10))\n","plt.imshow(img_A)\n","show_anns(img_A, masks_A)\n","plt.title(\"SAM Segmentations - Image A\")\n","plt.axis('off')\n","plt.show()\n","\n","plt.figure(figsize=(10, 10))\n","plt.imshow(img_B)\n","show_anns(img_B, masks_B)\n","plt.title(\"SAM Segmentations - Image B\")\n","plt.axis('off')\n","plt.show()\n","\n","for i, key in enumerate(new_keys):\n","    plt.figure(figsize=(4, 4))\n","    plt.imshow(mask_dict_B[key], cmap='gray')\n","    plt.title(f\"New Object {i+1}\")\n","    plt.axis('off')\n","    plt.show()\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[{"file_id":"https://github.com/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb","timestamp":1754037520109}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}